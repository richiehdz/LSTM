{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b32500a",
   "metadata": {},
   "source": [
    "This is the first try on implementing a LSTM on this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ff1b6bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importación de librerías para manejo de datos, visualización y deep learning\n",
    "# Incluye librerías para procesamiento, modelado y reproducibilidad de resultados\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "# Preprocesamiento y modelo LSTM\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Funciones personalizadas del proyecto\n",
    "from comparation2 import comparation2\n",
    "from Resumir_Datasets import resumir_datasets\n",
    "from unionDatasets import union_Datasets\n",
    "\n",
    "\n",
    "# Semilla fija para reproducibilidad de resultados\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "tf.random.set_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "88fde509",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo generado: datasets_resumidos\\resumen_cupos_2013A.xlsx\n",
      "Funcion de resumir los datasets ejecutada con exito\n",
      "Archivo generado: datasets_resumidos\\resumen_cupos_2013B.xlsx\n",
      "Funcion de resumir los datasets ejecutada con exito\n",
      "Archivo generado: datasets_resumidos\\resumen_cupos_2014A.xlsx\n",
      "Funcion de resumir los datasets ejecutada con exito\n",
      "Archivo generado: datasets_resumidos\\resumen_cupos_2014B.xlsx\n",
      "Funcion de resumir los datasets ejecutada con exito\n",
      "Archivo generado: datasets_resumidos\\resumen_cupos_2015A.xlsx\n",
      "Funcion de resumir los datasets ejecutada con exito\n",
      "Archivo generado: datasets_resumidos\\resumen_cupos_2015B.xlsx\n",
      "Funcion de resumir los datasets ejecutada con exito\n",
      "Archivo generado: datasets_resumidos\\resumen_cupos_2016A.xlsx\n",
      "Funcion de resumir los datasets ejecutada con exito\n",
      "Archivo generado: datasets_resumidos\\resumen_cupos_2016B.xlsx\n",
      "Funcion de resumir los datasets ejecutada con exito\n",
      "Archivo generado: datasets_resumidos\\resumen_cupos_2017A.xlsx\n",
      "Funcion de resumir los datasets ejecutada con exito\n",
      "Archivo generado: datasets_resumidos\\resumen_cupos_2017B.xlsx\n",
      "Funcion de resumir los datasets ejecutada con exito\n",
      "Archivo generado: datasets_resumidos\\resumen_cupos_2018A.xlsx\n",
      "Funcion de resumir los datasets ejecutada con exito\n",
      "Archivo generado: datasets_resumidos\\resumen_cupos_2018B.xlsx\n",
      "Funcion de resumir los datasets ejecutada con exito\n",
      "Archivo generado: datasets_resumidos\\resumen_cupos_2019A.xlsx\n",
      "Funcion de resumir los datasets ejecutada con exito\n",
      "Archivo generado: datasets_resumidos\\resumen_cupos_2019B.xlsx\n",
      "Funcion de resumir los datasets ejecutada con exito\n",
      "Archivo generado: datasets_resumidos\\resumen_cupos_2020A.xlsx\n",
      "Funcion de resumir los datasets ejecutada con exito\n",
      "Archivo generado: datasets_resumidos\\resumen_cupos_2020B.xlsx\n",
      "Funcion de resumir los datasets ejecutada con exito\n",
      "Archivo generado: datasets_resumidos\\resumen_cupos_2021A.xlsx\n",
      "Funcion de resumir los datasets ejecutada con exito\n",
      "Archivo generado: datasets_resumidos\\resumen_cupos_2021B.xlsx\n",
      "Funcion de resumir los datasets ejecutada con exito\n",
      "Archivo generado: datasets_resumidos\\resumen_cupos_2022A.xlsx\n",
      "Funcion de resumir los datasets ejecutada con exito\n",
      "Archivo generado: datasets_resumidos\\resumen_cupos_2022B.xlsx\n",
      "Funcion de resumir los datasets ejecutada con exito\n",
      "Archivo generado: datasets_resumidos\\resumen_cupos_2023A.xlsx\n",
      "Funcion de resumir los datasets ejecutada con exito\n",
      "Archivo generado: datasets_resumidos\\resumen_cupos_2023B.xlsx\n",
      "Funcion de resumir los datasets ejecutada con exito\n",
      "Archivo generado: datasets_resumidos\\resumen_cupos_2024A.xlsx\n",
      "Funcion de resumir los datasets ejecutada con exito\n",
      "Archivo generado: datasets_resumidos\\resumen_cupos_2024B.xlsx\n",
      "Funcion de resumir los datasets ejecutada con exito\n",
      "Archivo generado: datasets_resumidos\\resumen_cupos_2025A.xlsx\n",
      "Funcion de resumir los datasets ejecutada con exito\n"
     ]
    }
   ],
   "source": [
    "# Ejecuta la función que resume los datasets originales y guarda los archivos resumidos en la carpeta datasets_resumidos/\n",
    "# Entrada: Archivos como 2013A.xlsx, 2013B.xlsx, etc. en la carpeta datasets_originales/\n",
    "# Salida: Archivos como resumen_cupos_2013A.xlsx, resumen_cupos_2013B.xlsx, etc. en la carpeta datasets_resumidos/\n",
    "resumir_datasets()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2036d1f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando la funcion\n",
      "Archivo guardado como 'oferta_academica_unificada.csv\n",
      "Funcion de union de datasets ejecutada con exito\n"
     ]
    }
   ],
   "source": [
    "# Une todos los archivos resumidos en un solo archivo CSV llamado 'oferta_academica_unificada.csv'\n",
    "# Entrada: Archivos resumen_cupos_*.xlsx en datasets_resumidos/\n",
    "# Salida: Un solo archivo oferta_academica_unificada.csv con todas las materias y periodos juntos\n",
    "union_Datasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d29d4968",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carga el archivo unificado con todas las materias y periodos\n",
    "df = pd.read_csv(\"oferta_academica_unificada.csv\")\n",
    "\n",
    "# Elimina filas que no tienen datos clave (Materia, Total_Cupos, semestre_numerico)\n",
    "df = df.dropna(subset=['Materia', 'Total_Cupos', 'semestre_numerico'])\n",
    "\n",
    "# Codifica la columna 'Materia' a números para que pueda ser usada por el modelo, como un diccionario\n",
    "le = LabelEncoder()\n",
    "df['materia_codificada'] = le.fit_transform(df['Materia'])\n",
    "\n",
    "# Guarda el mapeo de códigos a nombres de materia para referencia futura\n",
    "diccionario_materias = dict(zip(df['materia_codificada'], df['Materia']))\n",
    "\n",
    "# Crea una columna con los cupos efectivamente usados (Total_Cupos - Residuos_Cupos)\n",
    "df['Cupos_Usados'] = df['Total_Cupos'] - df['Residuos_Cupos'].fillna(0)\n",
    "\n",
    "# Define las columnas que serán escaladas (normalizadas entre 0 y 1)\n",
    "escalar = ['Total_Secciones', 'semestre_numerico', 'Cupos_Usados', 'Residuos_Cupos']\n",
    "scaler = MinMaxScaler()\n",
    "df[escalar] = scaler.fit_transform(df[escalar])\n",
    "\n",
    "# Define las columnas de entrada (features) y la columna objetivo (target)\n",
    "features = ['materia_codificada', 'Total_Secciones', 'semestre_numerico', 'Residuos_Cupos', 'Cupos_Usados']\n",
    "target = 'Cupos_Usados'\n",
    "\n",
    "# Ejemplo de entrada:\n",
    "# | Materia         | Total_Cupos | Residuos_Cupos | semestre_numerico | ... |\n",
    "# |-----------------|-------------|----------------|-------------------|-----|\n",
    "# | PROGRAMACION    | 100         | 10             | 1                 | ... |\n",
    "#\n",
    "# Ejemplo de salida (después de procesamiento):\n",
    "# | materia_codificada | Total_Secciones | semestre_numerico | Residuos_Cupos | Cupos_Usados | ... |\n",
    "# |--------------------|-----------------|-------------------|----------------|--------------|-----|\n",
    "# | 0                  | 0.2             | 0.0               | 0.1            | 0.9          | ... |\n",
    "\n",
    "#   - Escalar los datos y codificar las etiquetas es fundamental para que el modelo LSTM pueda aprender patrones útiles y generalizar bien.\n",
    "#   - Tener los datos entre 0 y 1 ayuda a que el entrenamiento sea más eficiente y estable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9a3a62be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Secuencias creadas: (543, 6, 5)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Convierte una matriz de datos en secuencias para alimentar a una red LSTM.\n",
    "    data: np.array de tamaño (n, m) donde n=filas, m=features+target\n",
    "    pasos: int, número de pasos de la secuencia (ventana temporal)\n",
    "    Devuelve: X (secuencias de entrada), y (targets)\n",
    "    Ejemplo de entrada:\n",
    "        data = [[0, 0.2, 0.0, 0.1, 0.9, 0.9],   # fila 1\n",
    "                [0, 0.3, 0.1, 0.2, 0.8, 0.8],   # fila 2\n",
    "                ...]\n",
    "        pasos = 6\n",
    "    Ejemplo de salida:\n",
    "        X.shape = (n_secuencias, 6, 5)\n",
    "        y.shape = (n_secuencias,)\n",
    "\"\"\"\n",
    "def crear_secuencias(data, pasos):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - pasos):\n",
    "        X.append(data[i:i+pasos, :-1])\n",
    "        y.append(data[i+pasos, -1])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "pasos = 6 # Número de periodos a considerar en cada secuencia\n",
    "X_total, y_total = [], []\n",
    "\n",
    "# Para cada materia, crea las secuencias de entrada y salida\n",
    "for materia_id in df['materia_codificada'].unique():\n",
    "    \n",
    "    grupo = df[df['materia_codificada'] == materia_id].sort_values('semestre_numerico')\n",
    "    #print(grupo)\n",
    "    valores = grupo[features + [target]].values\n",
    "    if len(valores) > pasos:\n",
    "        X_seq, y_seq = crear_secuencias(valores, pasos)\n",
    "        X_total.append(X_seq)\n",
    "        y_total.append(y_seq)\n",
    "\n",
    "# Une todas las secuencias de todas las materias en un solo arreglo\n",
    "X = np.vstack(X_total)\n",
    "y = np.concatenate(y_total)\n",
    "\n",
    "# Ejemplo de salida:\n",
    "# X.shape = (total_secuencias, pasos, features)\n",
    "# y.shape = (total_secuencias,)\n",
    "print(\"✅ Secuencias creadas:\", X.shape)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "672546cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "17/17 [==============================] - 4s 11ms/step - loss: 0.0450\n",
      "Epoch 2/100\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0347\n",
      "Epoch 3/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0310\n",
      "Epoch 4/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0200\n",
      "Epoch 5/100\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0134\n",
      "Epoch 6/100\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.0095\n",
      "Epoch 7/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0105\n",
      "Epoch 8/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0106\n",
      "Epoch 9/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0108\n",
      "Epoch 10/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0102\n",
      "Epoch 11/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0089\n",
      "Epoch 12/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0085\n",
      "Epoch 13/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0090\n",
      "Epoch 14/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0086\n",
      "Epoch 15/100\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.0094\n",
      "Epoch 16/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0095\n",
      "Epoch 17/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0078\n",
      "Epoch 18/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0077\n",
      "Epoch 19/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0079\n",
      "Epoch 20/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0088\n",
      "Epoch 21/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0091\n",
      "Epoch 22/100\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0077\n",
      "Epoch 23/100\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0078\n",
      "Epoch 24/100\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0074\n",
      "Epoch 25/100\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.0080\n",
      "Epoch 26/100\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.0072\n",
      "Epoch 27/100\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.0079\n",
      "Epoch 28/100\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.0072\n",
      "Epoch 29/100\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0060\n",
      "Epoch 30/100\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0063\n",
      "Epoch 31/100\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0072\n",
      "Epoch 32/100\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.0069\n",
      "Epoch 33/100\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.0068\n",
      "Epoch 34/100\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.0062\n",
      "Epoch 35/100\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.0058\n",
      "Epoch 36/100\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.0068\n",
      "Epoch 37/100\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.0067\n",
      "Epoch 38/100\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.0058\n",
      "Epoch 39/100\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.0055\n",
      "Epoch 40/100\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.0057\n",
      "Epoch 41/100\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.0066\n",
      "Epoch 42/100\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.0070\n",
      "Epoch 43/100\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.0076\n",
      "Epoch 44/100\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.0077\n",
      "Epoch 45/100\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.0063\n",
      "Epoch 46/100\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.0051\n",
      "Epoch 47/100\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.0053\n",
      "Epoch 48/100\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.0054\n",
      "Epoch 49/100\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.0053\n",
      "Epoch 50/100\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0053\n",
      "Epoch 51/100\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0046\n",
      "Epoch 52/100\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.0049\n",
      "Epoch 53/100\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0054\n",
      "Epoch 54/100\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0048\n",
      "Epoch 55/100\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.0046\n",
      "Epoch 56/100\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0045\n",
      "Epoch 57/100\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0049\n",
      "Epoch 58/100\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0049\n",
      "Epoch 59/100\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0046\n",
      "Epoch 60/100\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0044\n",
      "Epoch 61/100\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0041\n",
      "Epoch 62/100\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.0041\n",
      "Epoch 63/100\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.0045\n",
      "Epoch 64/100\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0043\n",
      "Epoch 65/100\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0042\n",
      "Epoch 66/100\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0045\n",
      "Epoch 67/100\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0046\n",
      "Epoch 68/100\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0042\n",
      "Epoch 69/100\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0041\n",
      "Epoch 70/100\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0045\n",
      "Epoch 71/100\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0049\n",
      "Epoch 72/100\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0042\n",
      "Epoch 73/100\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0043\n",
      "Epoch 74/100\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0040\n",
      "Epoch 75/100\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0040\n",
      "Epoch 76/100\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0042\n",
      "Epoch 77/100\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.0039\n",
      "Epoch 78/100\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.0045\n",
      "Epoch 79/100\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0041\n",
      "Epoch 80/100\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0036\n",
      "Epoch 81/100\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0040\n",
      "Epoch 82/100\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0039\n",
      "Epoch 83/100\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0039\n",
      "Epoch 84/100\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0036\n",
      "Epoch 85/100\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0041\n",
      "Epoch 86/100\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.0045\n",
      "Epoch 87/100\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.0041\n",
      "Epoch 88/100\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0037\n",
      "Epoch 89/100\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0039\n",
      "Epoch 90/100\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0037\n",
      "Epoch 91/100\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.0038\n",
      "Epoch 92/100\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0036\n",
      "Epoch 93/100\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0032\n",
      "Epoch 94/100\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0033\n",
      "Epoch 95/100\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0041\n",
      "Epoch 96/100\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0035\n",
      "Epoch 97/100\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.0035\n",
      "Epoch 98/100\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.0041\n",
      "Epoch 99/100\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.0034\n",
      "Epoch 100/100\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0035\n"
     ]
    }
   ],
   "source": [
    "# Construcción del modelo LSTM con los mejores hiperparámetros encontrados\n",
    "# Estructura: 2 capas LSTM, 1 capa densa, 1 capa Dropout, 1 capa de salida\n",
    "\n",
    "model = Sequential()\n",
    "# First Layer\n",
    "model.add(LSTM(96, return_sequences=True, input_shape=(pasos, len(features))))\n",
    "\n",
    "# Second Layer\n",
    "model.add(LSTM(64, return_sequences=False))\n",
    "\n",
    "# 3rd Layer (Dense)\n",
    "model.add(Dense(192, activation=\"relu\")) # Toma las secuencias de la capa anterior y las transforma \n",
    "\n",
    "# 4th Layer (Dropout)\n",
    "model.add(Dropout(0.2)) #apaga aleatoriamente el 20% de las neuronas durante el entrenamiento para que generalice mejor\n",
    "\n",
    "# Final Output Layer\n",
    "model.add(Dense(1))\n",
    "\n",
    "# Entrenamiento del modelo\n",
    "#model.compile(optimizer=Adam(learning_rate=0.1), loss='mse')\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "history = model.fit(X, y, epochs=100, verbose=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "86a982f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 652ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n"
     ]
    }
   ],
   "source": [
    "# Predice el número de cupos usados para el próximo semestre de cada materia\n",
    "# Para cada materia, toma la última secuencia y predice el siguiente valor\n",
    "# El resultado se desescala para obtener el valor original\n",
    "\n",
    "predicciones = {}\n",
    "\n",
    "for materia_id in df['materia_codificada'].unique():\n",
    "    materia_df = df[df['materia_codificada'] == materia_id].sort_values('semestre_numerico')\n",
    "    valores = materia_df[features + [target]].values\n",
    "\n",
    "    if len(valores) >= pasos:\n",
    "        # Toma la última secuencia de la materia\n",
    "        secuencia = valores[-pasos:, :-1].reshape(1, pasos, len(features))\n",
    "        y_pred = model.predict(secuencia)[0][0]\n",
    "\n",
    "        # Prepara la fila para desescalar el resultado\n",
    "        ultima_fila_real = materia_df[escalar].values[-1].copy()\n",
    "        ultima_fila_real[-1] = y_pred\n",
    "        \n",
    "        # Desescala el resultado a su valor original\n",
    "        cupo_estimado = max(0, scaler.inverse_transform([ultima_fila_real])[0][-1])\n",
    "\n",
    "        nombre_materia = diccionario_materias.get(materia_id, f\"ID {materia_id}\")\n",
    "        predicciones[nombre_materia] = round(cupo_estimado)\n",
    "# Ejemplo de salida:\n",
    "# predicciones = {\n",
    "#   \"PROGRAMACION\": 145,\n",
    "#   \"ESTRUCTURAS DE DATOS\": 80,\n",
    "#   ...\n",
    "# }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "501d4832",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Archivo guardado: predicciones_cupos_proximo_semestre.xlsx\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Guarda las predicciones en un archivo Excel para su análisis posterior\n",
    "\n",
    "df_pred = pd.DataFrame(list(predicciones.items()), columns=[\"Materia\", \"Cupos_Estimados\"])\n",
    "df_pred.to_excel(\"predicciones_cupos_proximo_semestre.xlsx\", index=False)\n",
    "print(\"✅ Archivo guardado: predicciones_cupos_proximo_semestre.xlsx\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7b5efa5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                  Materia  Total_Cupos  Cupos_Usados  Cupos_Estimados  Error_Absoluto  Desviacion_%\n",
      "                                                                   ESTRUCTURAS DE DATOS I           40             1               13            12.0   1200.000000\n",
      "                             SEMINARIO DE SOLUCION DE PROBLEMAS DE ESTRUCTURAS DE DATOS I           24             9               30            21.0    233.333333\n",
      "                                                                  ESTRUCTURAS DE DATOS II           38             8                0             8.0   -100.000000\n",
      "                                                                 INGENIERIA DE SOFTWARE I           44            43                4            39.0    -90.697674\n",
      "                                                                               ALGORITMIA           40            26                9            17.0    -65.384615\n",
      "                           SEMINARIO DE SOLUCION DE PROBLEMAS DE INGENIERIA DE SOFTWARE I          123           123               44            79.0    -64.227642\n",
      "                                                                    METODOS MATEMATICOS I          183           161               59           102.0    -63.354037\n",
      "                                                      ESTADISTICA Y PROCESOS ESTOCASTICOS          207           182               67           115.0    -63.186813\n",
      "                                                               PROGRAMACION PARA INTERNET          183           180               69           111.0    -61.666667\n",
      "                                         SEMINARIO DE SOLUCION DE PROBLEMAS DE ALGORITMIA           56            56               22            34.0    -60.714286\n",
      "                            SEMINARIO DE SOLUCION DE PROBLEMAS DE ESTRUCTURAS DE DATOS II           62            14               22             8.0     57.142857\n",
      "                              SEMINARIO DE SOLUCION DE PROBLEMAS DE METODOS MATEMATICOS I          232           151               65            86.0    -56.953642\n",
      "                                                                             PROGRAMACION          228           142               65            77.0    -54.225352\n",
      "                                       SEMINARIO DE SOLUCION DE PROBLEMAS DE PROGRAMACION          223           132               63            69.0    -52.272727\n",
      "                             SEMINARIO DE SOLUCION DE PROBLEMAS DE METODOS MATEMATICOS II          334           223              110           113.0    -50.672646\n",
      "                                     SEMINARIO DE SOLUCION DE PROBLEMAS DE BASES DE DATOS          102            53               27            26.0    -49.056604\n",
      "                                                                   METODOS MATEMATICOS II          368           258              135           123.0    -47.674419\n",
      "                                                              SEGURIDAD DE LA INFORMACION          113           113               63            50.0    -44.247788\n",
      "                                                                         MINERIA DE DATOS          175           170               96            74.0    -43.529412\n",
      "                                                                INGENIERIA DE SOFTWARE II          159           159               92            67.0    -42.138365\n",
      "                   SEMINARIO DE SOLUCION DE PROBLEMAS DE SISTEMAS BASADOS EN CONOCIMIENTO          192           183              106            77.0    -42.076503\n",
      "                                                      ALMACENES DE DATOS (DATA WAREHOUSE)          193           191              111            80.0    -41.884817\n",
      "                                                       CLASIFICACION INTELIGENTE DE DATOS          248           220              128            92.0    -41.818182\n",
      "                                                                     CONTROL DE PROYECTOS          140            91               53            38.0    -41.758242\n",
      "SEMINARIO DE SOLUCION DE PROBLEMAS DE USO, ADAPTACION, EXPLOTACION DE SISTEMAS OPERATIVOS          199           199              117            82.0    -41.206030\n",
      "                                                             ADMINISTRACION DE SERVIDORES          152           134               80            54.0    -40.298507\n",
      "                                     USO, ADAPTACION Y EXPLOTACION DE SISTEMAS OPERATIVOS          280           216              130            86.0    -39.814815\n",
      "                                                         ADMINISTRACION DE BASES DE DATOS          216           189              115            74.0    -39.153439\n",
      "                                                         SISTEMAS BASADOS EN CONOCIMIENTO          252           205              126            79.0    -38.536585\n",
      "                                                                           BASES DE DATOS           38            27               21             6.0    -22.222222\n",
      "                                                                               HIPERMEDIA           35            33               27             6.0    -18.181818\n",
      "                                                                 TEORIA DE LA COMPUTACION           38            38               41             3.0      7.894737\n",
      "\n",
      "📊 MAE (promedio de error absoluto en cupos usados): 59.62\n",
      "📉 MAPE (porcentaje de error promedio en cupos usados): 91.10%\n"
     ]
    }
   ],
   "source": [
    "# Compara las predicciones con los valores reales y muestra métricas de error\n",
    "\n",
    "comparation2()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
